{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract model\n",
    "! wget http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/models/pytorch/resnet50_128_pytorch.tar.gz\n",
    "! mkdir model\n",
    "! tar -xvzf resnet50_128_pytorch.tar.gz -C model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need this\n",
    "# ! pip3 install gdown\n",
    "# ! pip3 install shutil\n",
    "# ! pip3 install tqdm\n",
    "# ! sudo apt install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download names\n",
    "! mkdir data\n",
    "! gdown https://drive.google.com/uc?id=1zRtJzbwomoRVQg5oFr621zpI0-4MnIFk\n",
    "! mv names.tsv ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "! gdown https://drive.google.com/uc?id=1jvjeTj8bJDpHvq6pJYlfxGnlLEKAHAxO\n",
    "! mkdir data/test\n",
    "! unzip test.zip -d data/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import torch\n",
    "import glob as gb\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import pylab as plt\n",
    "import model.resnet50_128 as model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "from pytorch_feature_extractor import initialize_model, image_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data/test/folder1/’: File exists\r\n",
      "mkdir: cannot create directory ‘data/test/folder2/’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "folder1 = 'data/test/folder1/'\n",
    "folder2 = 'data/test/folder2/'\n",
    "test_folder = 'data/test/test/'\n",
    "names_file = 'data/names.tsv'\n",
    "\n",
    "!mkdir 'data/test/folder1/' & mkdir 'data/test/folder2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare datasets for testing\n",
    "names = pd.read_csv(names_file, delimiter='\\t', names=['class', 'image'])\n",
    "names['image'] = names['image'].apply(str).apply(lambda x: test_folder+f'{x}.jpg')\n",
    "\n",
    "sample = []\n",
    "for i in range(500):\n",
    "    row = names[names['class'] == i].iloc[0]\n",
    "    sample.append((row['class'], row['image']))\n",
    "\n",
    "# move 1 image from each class for prediction\n",
    "for i in sample:\n",
    "    shutil.copy(i[1], folder1+i[1].split('/')[-1])\n",
    "    \n",
    "# sample first 1000 images\n",
    "for i in names['image'][:1000]:\n",
    "    shutil.copy(i, folder2+i.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(folder1:str, folder2:str) -> list:\n",
    "    images1 = gb.glob(folder1 + '*.jpg')\n",
    "    images2 = gb.glob(folder2 + '*.jpg')\n",
    "    model_eval = initialize_model()\n",
    "    folder1_face_feats = image_encoding(model_eval, images1)\n",
    "    folder2_face_feats = image_encoding(model_eval, images2)\n",
    "    \n",
    "    S = np.dot(folder2_face_feats, folder1_face_feats.T)\n",
    "\n",
    "    return [(images2[i], images1[images.argmax()]) for i, images in enumerate(S)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_once(folder1:str, image2:str) -> str:\n",
    "    images1 = gb.glob(folder1 + '*.jpg')\n",
    "    images2 = gb.glob(image2)\n",
    "    model_eval = initialize_model()\n",
    "    folder1_face_feats = image_encoding(model_eval, images1)\n",
    "    folder2_face_feats = image_encoding(model_eval, images2)\n",
    "\n",
    "    S = np.dot(folder2_face_feats, folder1_face_feats.T)\n",
    "\n",
    "    return images1[S.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add is deprecated:\n",
      "\tadd(Tensor input, Number alpha, Tensor other, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd(Tensor input, Tensor other, *, Number alpha, Tensor out)\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n",
      "100%|██████████| 63/63 [00:30<00:00,  2.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# small test\n",
    "# (240, 224, 3)\n",
    "predictions = predict(folder1, folder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:15<00:00,  2.01it/s]\n",
      "  0%|          | 11/10556 [00:06<1:44:08,  1.69it/s]"
     ]
    }
   ],
   "source": [
    "# big test\n",
    "predictions = predict(folder1, test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:05<00:00,  5.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data/test/folder1/0.jpg'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predict_once(folder1, 'data/test/folder2/1.jpg')\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.read_csv(names_file, delimiter='\\t', names=['class', 'image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceImagesClassDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Images Dataset only for printing\n",
    "    \"\"\"\n",
    "    def __init__(self, predictions, names):\n",
    "        super().__init__()\n",
    "\n",
    "        self.predictions = predictions\n",
    "        self.names = names\n",
    "\n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file).convert('RGB')\n",
    "        image.load()\n",
    "        return image\n",
    "\n",
    "    def _prepare_sample(self, image):\n",
    "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "         return len(predictions)\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        predicted = self._prepare_sample(self.load_sample(self.predictions[index][0]))\n",
    "        source = self._prepare_sample(self.load_sample(self.predictions[index][1]))\n",
    "        \n",
    "        source_num = predictions[index][0].split('/')[-1].split('.')[-2]\n",
    "        predicted_num = predictions[index][1].split('/')[-1].split('.')[-2]\n",
    "        \n",
    "        source_class = names[names['image'] == int(source_num)]['class'].iloc[0]\n",
    "        predicted_class = names[names['image'] == int(predicted_num)]['class'].iloc[0]\n",
    "        \n",
    "        return predicted, source, predicted_class, source_class\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_images_class_dataset = FaceImagesClassDataset(predictions, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ni = 4\n",
    "RESCALE_SIZE = 224\n",
    "\n",
    "fig, ax = plt.subplots(nrows=Ni, ncols=2,figsize=(10, 10), \\\n",
    "                        sharey=True, sharex=True)\n",
    "\n",
    "for i in range(Ni):\n",
    "    for fig_x in ax.flatten():\n",
    "        random_characters = int(np.random.uniform(0, len(predictions)))\n",
    "        source, predicted, source_class, predicted_class = face_images_class_dataset[random_characters]\n",
    "        \n",
    "        ax[i ,0].imshow(source)\n",
    "        ax[i ,0].set_title('Source class: ' + str(source_class))\n",
    "        ax[i ,1].imshow(predicted)\n",
    "        ax[i ,1].set_title('Predicted class: ' + str(predicted_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceClassDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class Dataset only for accuracy score \n",
    "    \"\"\"\n",
    "    def __init__(self, predictions, names):\n",
    "        super().__init__()\n",
    "\n",
    "        self.predictions = predictions\n",
    "        self.names = names\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "         return len(predictions)\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        source_num = predictions[index][0].split('/')[-1].split('.')[-2]\n",
    "        predicted_num = predictions[index][1].split('/')[-1].split('.')[-2]\n",
    "        \n",
    "        source_class = names[names['image'] == int(source_num)]['class'].iloc[0]\n",
    "        predicted_class = names[names['image'] == int(predicted_num)]['class'].iloc[0]\n",
    "        \n",
    "        return predicted_class, source_class\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_class_dataset = FaceClassDataset(predictions, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_accuracy(face_class_dataset):\n",
    "    acum = 0\n",
    "    for i, face_pair in tqdm(enumerate(face_class_dataset), \n",
    "                             total = len(face_class_dataset)):\n",
    "        acum += int(face_pair[0] == face_pair[1])\n",
    "    return acum/len(predictions)\n",
    "\n",
    "face_accuracy(face_class_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
